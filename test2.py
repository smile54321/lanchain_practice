# Langchain íŒ¨í‚¤ì§€ë“¤
from langchain.prompts import PromptTemplate
from langchain.chains.summarize import load_summarize_chain
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chat_models import BedrockChat
import boto3
import json
from langchain.document_loaders import YoutubeLoader
import streamlit as st
import requests
import pandas as pd
import os
import io
import base64
from io import BytesIO
from PIL import Image

session = boto3.Session()

bedrock = session.client(
    service_name='bedrock-runtime',
    region_name='us-east-1',
    endpoint_url="https://bedrock-runtime.us-east-1.amazonaws.com"
)

#ì´ë¯¸ì§€ ìƒì„±
bedrock_model_id = "stability.stable-diffusion-xl-v0" # stability.stable-diffusion-xl-v1ë¡œ ë°”ê¿”ë³´ì„¸ìš”.
#ë°”ì´íŠ¸ ì´ë¯¸ì§€ í˜•íƒœë¡œ ë³€í™˜
def get_response_image_from_payload(response): 

    payload = json.loads(response.get('body').read()) 
    images = payload.get('artifacts')
    image_data = base64.b64decode(images[0].get('base64'))

    return BytesIO(image_data) 

def get_image_response(prompt_content): 
    
    request_body = json.dumps({"text_prompts": 
                               [ {"text": prompt_content } ], 
                               "cfg_scale": 9, 
                               "steps": 80, }) 
    #ë°”ì´íŠ¸ í˜•íƒœ
    response = bedrock.invoke_model(body=request_body, modelId=bedrock_model_id)
    
    output = get_response_image_from_payload(response) 
     
    return output

st.title("ì˜ìƒ ì¸ë„¤ì¼ ì œì‘ ğŸ‘¨â€ğŸ¨")

st.image('https://wikidocs.net/images/page/215361/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%ED%99%94%EA%B0%80.png', width=200)

#ìœ íŠœë¸Œ URL ë„£ëŠ” ì¹¸
youtube_video_url=st.text_area('ì¸ë„¤ì¼ë¡œ ë§Œë“¤ ì˜ìƒ URLì„ ì…ë ¥í•˜ì„¸ìš”.') #URL ë„£ëŠ” ì¹¸ í• ë‹¹
a=st.button('printing')
if a:
        #ìœ íŠœë¸Œ ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œí•˜ê¸°
    loader = YoutubeLoader.from_youtube_url(youtube_video_url)
    transcript = loader.load()
    script=transcript[0].page_content
# ì–¸ì–´ëª¨ë¸ ì„¤ì •
    llm = BedrockChat(model_kwargs={"temperature": 0},
                        model_id="anthropic.claude-v2",
                        client=bedrock
                    )
# í”„ë¡¬í”„íŠ¸ ì„¤ì •
    prompt = PromptTemplate(
    template="""ë°±í‹±ìœ¼ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ì „ì‚¬ë³¸ì„ ì´ìš©í•´ í•´ë‹¹ ìœ íŠœë¸Œ ë¹„ë””ì˜¤ë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”. \
    ```{text}```
    """, input_variables=["text"]
    )
    combine_prompt = PromptTemplate(
    template="""Combine all the youtube video transcripts provided within backticks \
    ```{text}```
    Provide a concise summary between 5 to 10 sentences.
    """, input_variables=["text"]
    )
# LangChainì„ í™œìš©í•˜ì—¬ ê¸´ ê¸€ ìš”ì•½í•˜ê¸°
# ê¸€ ìª¼ê°œê¸°
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=4000, chunk_overlap=0)
    texts = text_splitter.create_documents([script])

# ìš”ì•½í•˜ê¸°
    chain = load_summarize_chain(llm, chain_type="map_reduce", verbose=False,
                            map_prompt=prompt, combine_prompt=combine_prompt)
    summerize = chain.run(texts)


#ìš”ì•½í•œ ë‚´ìš© ë„£ì–´ì„œ ì´ë¯¸ì§€ ìƒì„±
    input_text = summerize
    if input_text:
        try:
            image = get_image_response(input_text)
            st.image(image)
        except:
            st.error("ìš”ì²­ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")
        else:
            st.warning("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”")